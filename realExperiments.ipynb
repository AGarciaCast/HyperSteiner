{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe53e30",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a8ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHCv2.4.86 released 2022-05-30 works!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import seaborn as sns\n",
    "from src.smithMethods import *\n",
    "from src.utils.delaunay2d import *\n",
    "from src.utils.hyperbolicWrappedGaussian import disc_pt_to_hyperboloid, hyperbolic_sampling, proj\n",
    "from scipy.spatial.qhull import QhullError\n",
    "from collections import defaultdict \n",
    "from phcpy.phcpy2c3 import py2c_set_seed\n",
    "import time\n",
    "from matplotlib.lines import Line2D\n",
    "import networkx as nx\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle \n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "import statistics\n",
    "import biotite.sequence.phylo as phylo\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "FIG_PATH =  Path(\"./Figures/Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666a0c3e",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2530936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSteinerTree(steinerGraph, verticesDict, mstGraph, edgesDT, space=\"Klein\", additional=\"MST\", title='Title'):\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,6), dpi=200)\n",
    "    ax = fig.add_subplot(111, aspect='equal') \n",
    "    \n",
    "    if space==\"Klein\" or space==\"Poincare\":\n",
    "        circ = plt.Circle((0, 0), radius=1, edgecolor='black', facecolor='None', linewidth=3, alpha=0.5)\n",
    "        ax.add_patch(circ)\n",
    "        \n",
    "    if mstGraph is not None or edgesDT is not None:\n",
    "        if additional == \"MST\":\n",
    "            H = nx.Graph(mstGraph)\n",
    "        elif additional == \"DT\":\n",
    "            H = nx.Graph([[f\"T{p}\" for p in edge] for edge in edgesDT])\n",
    "        else:\n",
    "            raise ValueError(\"additional should either 'MST' or 'DT'\")\n",
    "\n",
    "        nx.draw_networkx_edges(H, pos=verticesDict, style='--', alpha=0.4)\n",
    "    \n",
    "    G = nx.Graph(steinerGraph)\n",
    "    G.add_node(\"T0\")\n",
    "    color_map = []\n",
    "\n",
    "    for node in G:\n",
    "        if node[0]==\"S\":\n",
    "            color_map.append('tab:blue')\n",
    "        else: \n",
    "            color_map.append('tab:red') \n",
    "\n",
    "    nx.draw(G, node_color=color_map, pos=verticesDict,node_size=5) #node_size=50\n",
    "    \n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='Terminal',markerfacecolor='tab:red', markersize=5), #markersize=12\n",
    "        Line2D([0], [0], marker='o', color='w', label='Steiner',markerfacecolor='tab:blue', markersize=5), #markersize=12       \n",
    "    ]\n",
    "\n",
    "    \n",
    "    plt.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.10, 1))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #fig.savefig(FIG_PATH / f\"{space}_dtSMT.png\")\n",
    "    \n",
    "    plt.savefig(title+'.pdf')\n",
    "    #plt.show()\n",
    "\n",
    "def klein2poincare(z_klein):\n",
    "    norm_squared = z_klein[0]**2+z_klein[1]**2 \n",
    "    denom = 1+np.sqrt(1-norm_squared)\n",
    "    z_poincare = z_klein[0]/denom, z_klein[1]/denom\n",
    "    return np.array(z_poincare)\n",
    "\n",
    "def verticesDict_klein2poincare(verticesDict):\n",
    "    verticesDict_Poincare = verticesDict\n",
    "    for key in verticesDict_Poincare.keys():\n",
    "        verticesDict_Poincare[key] = klein2poincare(verticesDict_Poincare[key])\n",
    "    return verticesDict_Poincare\n",
    "\n",
    "def distance_klein(p,q): #with p and q in euclidean coordinates and their norm<1\n",
    "    norm_p = (p**2).sum(-1)\n",
    "    norm_q = (q**2).sum(-1)\n",
    "    dot_pq = (p*q).sum(-1)\n",
    "    return np.arccosh((1-dot_pq)/np.sqrt((1-norm_p)*(1-norm_q)))  \n",
    "\n",
    "def distance_matrix(pts, dist=distance_klein):\n",
    "    return dist(np.expand_dims(pts, 0), np.expand_dims(pts, 1)) \n",
    "\n",
    "def build_hyperbolically_weighted_adjacency_matrix(Graph, verticesDict, total_nmbr_terminal = 2047):\n",
    "    #it can be that some terminals are missing in verticesDict. \n",
    "    max_idx_steiner = 0\n",
    "    for edge in Graph:\n",
    "        for vertex in edge:\n",
    "            if list(vertex)[0] == 'S':\n",
    "                idx_steiner = ''\n",
    "                for l in vertex[1:]:\n",
    "                    idx_steiner=idx_steiner+l \n",
    "                idx_steiner = int(idx_steiner)                \n",
    "                if idx_steiner > max_idx_steiner:\n",
    "                    max_idx_steiner = idx_steiner\n",
    "    total_nmbr_steiner = max_idx_steiner + 1 \n",
    "    nmbr_nodes = total_nmbr_terminal + total_nmbr_steiner\n",
    "    hyperbolically_weighted_adjacency_matrix = np.zeros((nmbr_nodes, nmbr_nodes))    \n",
    "    \n",
    "    for edge in Graph:\n",
    "        indices = []\n",
    "        \n",
    "        for vertex in edge:\n",
    "            \n",
    "            nmbr_str = ''\n",
    "            for l in vertex[1:]:\n",
    "                nmbr_str=nmbr_str+l \n",
    "            nmbr_integer = int(nmbr_str)\n",
    "            \n",
    "            if list(vertex)[0] == 'T':\n",
    "                index = nmbr_integer\n",
    "            else: #i.e. list(vertex)[0] == 'S'\n",
    "                index = total_nmbr_terminal + nmbr_integer\n",
    "            indices.append(index)\n",
    "        \n",
    "        hyperbolic_dist_edge = distance_klein(verticesDict[edge[0]],verticesDict[edge[1]])\n",
    "        hyperbolically_weighted_adjacency_matrix[indices[0]][indices[1]] = hyperbolic_dist_edge \n",
    "        hyperbolically_weighted_adjacency_matrix[indices[1]][indices[0]] = hyperbolic_dist_edge \n",
    "\n",
    "    return hyperbolically_weighted_adjacency_matrix\n",
    "\n",
    "def normalize(matrix): #or vector\n",
    "    normalized_matrix = (1/np.max(matrix))*matrix\n",
    "    return normalized_matrix\n",
    "\n",
    "def normalize_embedding(z):\n",
    "\n",
    "    #need to normalize to get norms<1 in order to build the Hyperbolic Voronoi Diagram\n",
    "    z_norms=[]\n",
    "    for v in z:\n",
    "        z_norms.append(np.linalg.norm(v))\n",
    "    max_z_norms = max(z_norms)+0.001 #small perturbation of 0.001 to not have the maximal norm being normalized to exactly 1 because all the normalized norms should be stricly inferior to 1   \n",
    "\n",
    "    z_normalized=[]\n",
    "    for i in range(len(z)):\n",
    "            z_normalized.append([z[i][0]/max_z_norms, z[i][1]/max_z_norms])\n",
    "\n",
    "    return z_normalized\n",
    "\n",
    "def poincare2klein(z_normalized):\n",
    "    #Convert from PoincarÃ© to Beltrami-Cayley-Klein model latent representation\n",
    "    z_beltrami = []\n",
    "    for i in range(len(z_normalized)):\n",
    "        norm_squared = z_normalized[i][0]**2+z_normalized[i][1]**2 \n",
    "        z_beltrami.append([2*z_normalized[i][0]/(1+norm_squared), 2*z_normalized[i][1]/(1+norm_squared)])\n",
    "\n",
    "    z_beltrami=np.array(z_beltrami)\n",
    "    return z_beltrami\n",
    "\n",
    "def get_disconnected_indices(planaria_klein, verticesDict):\n",
    "    disconnected_indices = [] \n",
    "    for i in range(planaria_klein.shape[0]):\n",
    "        if 'T'+str(i) not in verticesDict.keys():\n",
    "            disconnected_indices.append(i) \n",
    "    return disconnected_indices\n",
    "\n",
    "def build_nj_adjacency_matrix(nj_graph, total_nmbr_terminal = 2047):\n",
    "\n",
    "    max_idx_steiner = 0\n",
    "    for edge in nj_graph:\n",
    "        for vertex in edge:\n",
    "            if list(vertex)[0] == 'S':\n",
    "                idx_steiner = ''\n",
    "                for l in vertex[1:]:\n",
    "                    idx_steiner=idx_steiner+l \n",
    "                idx_steiner = int(idx_steiner)                \n",
    "                if idx_steiner > max_idx_steiner:\n",
    "                    max_idx_steiner = idx_steiner\n",
    "    total_nmbr_steiner = max_idx_steiner + 1 \n",
    "    nmbr_nodes = total_nmbr_terminal + total_nmbr_steiner\n",
    "    nj_adjacency_matrix = np.zeros((nmbr_nodes, nmbr_nodes))\n",
    "    \n",
    "    for edge in nj_graph:\n",
    "        indices = []\n",
    "        \n",
    "        for vertex in edge:\n",
    "            \n",
    "            nmbr_str = ''\n",
    "            for l in vertex[1:]:\n",
    "                nmbr_str=nmbr_str+l \n",
    "            nmbr_integer = int(nmbr_str)\n",
    "            \n",
    "            if list(vertex)[0] == 'T':\n",
    "                index = nmbr_integer\n",
    "            else: #i.e. list(vertex)[0] == 'S'\n",
    "                index = total_nmbr_terminal + nmbr_integer\n",
    "            indices.append(index)\n",
    "        \n",
    "        dist_edge = nj_graph[edge]\n",
    "        nj_adjacency_matrix[indices[0]][indices[1]] = dist_edge \n",
    "        nj_adjacency_matrix[indices[1]][indices[0]] = dist_edge \n",
    "\n",
    "    return nj_adjacency_matrix\n",
    "\n",
    "def neighbor_joining(points, dist_matrix, space=\"Klein\"):\n",
    "    if space not in [\"Klein\", \"Euclidean\", \"Half\"]:\n",
    "        raise ValueError(\"space should be either 'Klein', 'Euclidean' or 'Half'\")\n",
    "    \n",
    "    tree = phylo.neighbor_joining(dist_matrix)\n",
    "    G = tree.as_graph().to_undirected()\n",
    "    \n",
    "    mapping = dict()\n",
    "    count = 0\n",
    "    for n in G.nodes:\n",
    "        if type(n) is tuple:\n",
    "            mapping[n] = f\"S{count}\"\n",
    "            count+=1\n",
    "        else:\n",
    "            mapping[n] = f\"T{n}\"\n",
    "    \n",
    "    G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "    return nx.get_edge_attributes(G,'distance')\n",
    "\n",
    "\n",
    "def run_realbio_exp(percentage, planaria_klein, planaria_pseudotime_groundtruth):\n",
    "# This is the percentage of missing data i.e. (100-percentage)% of data are considered\n",
    "    threshold = int((100-percentage)/100 * planaria_klein.shape[0])\n",
    "\n",
    "    nmbr_permutation = 100 # number of permutations i.e. of different random sampling of the data\n",
    "\n",
    "\n",
    "    random_seed = 0\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    root_idx = 0\n",
    "\n",
    "\n",
    "    ######################\n",
    "\n",
    "    corr_dict = {'steiner':[], 'mst': [], 'nj':[]}\n",
    "    frobenius_dict = {'steiner':[], 'mst': [], 'nj':[]}\n",
    "    time_dict = {'steiner':[], 'mst': [], 'nj':[]}\n",
    "\n",
    "    print('random_seed', random_seed)\n",
    "    print('percentage', percentage)\n",
    "    print()\n",
    "\n",
    "    for permutation in range(nmbr_permutation):\n",
    "        print('permutation', permutation)\n",
    "\n",
    "        # We keep the root index 0 at 0, and permute the rest\n",
    "        permutation_indices = np.random.permutation(np.arange(planaria_klein.shape[0])[1:])\n",
    "        permutation_indices = np.append(root_idx, permutation_indices)\n",
    "\n",
    "        points_klein = planaria_klein[permutation_indices, :][:threshold]\n",
    "        pseudotime_groundtruth = planaria_pseudotime_groundtruth[permutation_indices][:threshold]\n",
    "        #normalize pseudotime_groundtruth\n",
    "        pseudotime_groundtruth_normalized = normalize(pseudotime_groundtruth)\n",
    "        nmbr_terminal=points_klein.shape[0]\n",
    "\n",
    "        #NJ\n",
    "        start_time = time.time()\n",
    "        #print('Computing distance matrix for NJ...')\n",
    "        distance_matrix_points_klein = distance_matrix(points_klein)\n",
    "        njGraph = neighbor_joining(points_klein, distance_matrix_points_klein) \n",
    "        adjacency_matrix_nj = build_nj_adjacency_matrix(njGraph, total_nmbr_terminal=nmbr_terminal)\n",
    "\n",
    "        csr_adjacency_matrix_nj = csr_matrix(adjacency_matrix_nj)\n",
    "        del adjacency_matrix_nj\n",
    "        #only distance to the root which is at index root_idx\n",
    "        shortest_path_distance_matrix_nj_all = dijkstra(csgraph=csr_adjacency_matrix_nj, directed=False, indices=root_idx)\n",
    "        shortest_path_distance_matrix_nj_terminal = shortest_path_distance_matrix_nj_all[:nmbr_terminal]\n",
    "        normalized_shortest_path_distance_matrix_nj_terminal = normalize(shortest_path_distance_matrix_nj_terminal)\n",
    "        end_time = time.time()\n",
    "        time_nj = end_time - start_time\n",
    "        corr_nj = np.corrcoef(pseudotime_groundtruth_normalized, normalized_shortest_path_distance_matrix_nj_terminal)[0][1] \n",
    "        frobenius_nj = np.linalg.norm(normalized_shortest_path_distance_matrix_nj_terminal-pseudotime_groundtruth_normalized)\n",
    "        #print('corr_nj', corr_nj)\n",
    "        print('frobenius_nj', frobenius_nj)\n",
    "        print('time_nj', time_nj)\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "        steinerGraph, verticesDict, ratio, mstGraph, mstTime, edgesDT, FST3, numFST4 = heuristicMSTpipeline(points_klein, \n",
    "                                                                                   space=\"Klein\", \n",
    "                                                                                   triangMeth=\"DT\", \n",
    "                                                                                   maxgroup=4, \n",
    "                                                                                   nIters=3, \n",
    "                                                                                   convDiff=1e-1, \n",
    "                                                                                   dist2Points=1e-5,\n",
    "                                                                                   precise=True)\n",
    "        #plotSteinerTree(steinerGraph, verticesDict, mstGraph, edgesDT, space=\"Klein\", title='Planaria_rdmseed'+str(random_seed)+'_percent'+str(percentage)+'_permutation'+str(permutation)+'_Klein') \n",
    "        #verticesDict_Poincare = verticesDict_klein2poincare(verticesDict)\n",
    "        #plotSteinerTree(steinerGraph, verticesDict_Poincare, mstGraph, edgesDT, space=\"Poincare\", title='Planaria_rdmseed'+str(random_seed)+'_percent'+str(percentage)+'_permutation'+str(permutation)+'_Poincare') \n",
    "\n",
    "        hyperbolically_weighted_adjacency_matrix_steiner = build_hyperbolically_weighted_adjacency_matrix(steinerGraph, verticesDict, total_nmbr_terminal=nmbr_terminal)\n",
    "\n",
    "        csr_hyperbolically_weighted_adjacency_matrix_steiner = csr_matrix(hyperbolically_weighted_adjacency_matrix_steiner)\n",
    "        del hyperbolically_weighted_adjacency_matrix_steiner\n",
    "        #only distance to the root which is at index 6\n",
    "        shortest_path_distance_matrix_steiner_all = dijkstra(csgraph=csr_hyperbolically_weighted_adjacency_matrix_steiner, directed=False, indices=root_idx)\n",
    "        shortest_path_distance_matrix_steiner_terminal = shortest_path_distance_matrix_steiner_all[:nmbr_terminal]\n",
    "        normalized_shortest_path_distance_matrix_steiner_terminal = normalize(shortest_path_distance_matrix_steiner_terminal)    \n",
    "        end_time = time.time()\n",
    "        time_steiner = end_time - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        hyperbolically_weighted_adjacency_matrix_mst = build_hyperbolically_weighted_adjacency_matrix(mstGraph, verticesDict, total_nmbr_terminal=nmbr_terminal)         \n",
    "        csr_hyperbolically_weighted_adjacency_matrix_mst = csr_matrix(hyperbolically_weighted_adjacency_matrix_mst)\n",
    "        del hyperbolically_weighted_adjacency_matrix_mst\n",
    "        shortest_path_distance_matrix_mst_all = dijkstra(csgraph=csr_hyperbolically_weighted_adjacency_matrix_mst, directed=False, indices=root_idx)\n",
    "        shortest_path_distance_matrix_mst_terminal = shortest_path_distance_matrix_mst_all[:nmbr_terminal]\n",
    "        normalized_shortest_path_distance_matrix_mst_terminal = normalize(shortest_path_distance_matrix_mst_terminal)\n",
    "        end_time = time.time()\n",
    "        time_mst = end_time - start_time + mstTime\n",
    "        \n",
    "        corr_steiner = np.corrcoef(pseudotime_groundtruth_normalized, normalized_shortest_path_distance_matrix_steiner_terminal)[0][1] \n",
    "        frobenius_steiner = np.linalg.norm(normalized_shortest_path_distance_matrix_steiner_terminal-pseudotime_groundtruth_normalized)\n",
    "\n",
    "        corr_mst = np.corrcoef(pseudotime_groundtruth_normalized, normalized_shortest_path_distance_matrix_mst_terminal)[0][1] \n",
    "        frobenius_mst = np.linalg.norm(normalized_shortest_path_distance_matrix_mst_terminal-pseudotime_groundtruth_normalized)\n",
    "\n",
    "        #print('corr_steiner', corr_steiner)\n",
    "        print('frobenius_steiner', frobenius_steiner)\n",
    "        print('time_steiner', time_steiner)\n",
    "\n",
    "        #print('corr_mst', corr_mst)   \n",
    "        print('frobenius_mst', frobenius_mst)\n",
    "        print('time_mst', time_mst)\n",
    "        print()\n",
    "\n",
    "        corr = {'nj':corr_nj, 'steiner':corr_steiner, 'mst':corr_mst}\n",
    "        frobenius = {'nj':frobenius_nj, 'steiner':frobenius_steiner, 'mst':frobenius_mst}\n",
    "        cpu_time = {'nj':time_nj, 'steiner':time_steiner, 'mst':time_mst}\n",
    "\n",
    "        for key in ['nj', 'steiner', 'mst']:\n",
    "            corr_dict[key].append(corr[key])\n",
    "            frobenius_dict[key].append(frobenius[key])\n",
    "            time_dict[key].append(cpu_time[key])\n",
    "\n",
    "    # Save results\n",
    "    name = 'Results/Real/Planaria_rdmseed'+str(random_seed)+'_percent'+str(percentage)+'_nmbrpermutation'+str(nmbr_permutation) \n",
    "    with open(name+'_corr_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(corr_dict, f)  \n",
    "    with open(name+'_frobenius_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(frobenius_dict, f)\n",
    "    with open(name+'_time_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(time_dict, f)\n",
    "\n",
    "    print('DONE!') \n",
    "    non_valid_perm = [] # this is to remove samplings leading to numerical issues for the MST and Steiner\n",
    "    for i in range(len(corr_dict['steiner'])):\n",
    "        if math.isnan(corr_dict['steiner'][i]):\n",
    "            non_valid_perm.append(i) \n",
    "    valid_perm = np.arange(len(corr_dict['steiner']))\n",
    "    valid_perm = np.delete(valid_perm, non_valid_perm)\n",
    "    print('non_valid_perm:', non_valid_perm)    \n",
    "\n",
    "    print('random seed:', random_seed)\n",
    "    print('percentage:', percentage)\n",
    "    print('number of permutations:', nmbr_permutation)\n",
    "    max_perm = nmbr_permutation # option to consider the max_perm first permutations\n",
    "    print('max perm', max_perm)\n",
    "    print()\n",
    "    for key in ['nj', 'steiner', 'mst']:\n",
    "        print(key)\n",
    "        #print('corr mean+-std '+str(statistics.mean(np.array(corr_dict[key])[valid_perm][:max_perm]))+'+-'+str(statistics.stdev(np.array(corr_dict[key])[valid_perm][:max_perm])))\n",
    "        print('frobenius mean+-std '+str(statistics.mean(np.array(frobenius_dict[key])[valid_perm][:max_perm]))+'+-'+str(statistics.stdev(np.array(frobenius_dict[key])[valid_perm][:max_perm])))    \n",
    "        print('time mean+-std '+str(statistics.mean(np.array(time_dict[key])[valid_perm][:max_perm]))+'+-'+str(statistics.stdev(np.array(time_dict[key])[valid_perm][:max_perm])))    \n",
    "        print()\n",
    "\n",
    "def run_realbio_exp_all(planaria_klein, planaria_pseudotime_groundtruth): #to run from percentages 95 to 75, by step of 2.5, and for 100 samplings at each percentage\n",
    "    for i in range(95, 74, -5):\n",
    "        run_realbio_exp(i, planaria_klein, planaria_pseudotime_groundtruth)\n",
    "        if i > 75:\n",
    "            run_realbio_exp(i-2.5, planaria_klein, planaria_pseudotime_groundtruth)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085d247",
   "metadata": {},
   "source": [
    "# Load processed data and run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4387f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = Path(\"./Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d71266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_PATH / 'planaria_klein_cleaned.npy', 'rb') as f:\n",
    "    data = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a486806",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_PATH / 'planaria_pseudotime_groundtruth_cleaned.npy', 'rb') as f:\n",
    "    groundtruth = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8441bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_realbio_exp_all(data, groundtruth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eea6ef",
   "metadata": {},
   "source": [
    "# Load the results and rearrange the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8031dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "random_seed = 0\n",
    "nmbr_permutation = 100 # number of permutations\n",
    "percentages = [95, 92.5, 90, 87.5, 85, 82.5, 80, 77.5, 75]\n",
    "results = {}\n",
    "for percentage in percentages:\n",
    "    \n",
    "    results[str(percentage)] = {'correlation':[], 'frobenius':[]}\n",
    "    name = 'Results/Real/Planaria_rdmseed'+str(random_seed)+'_percent'+str(percentage)+'_nmbrpermutation'+str(nmbr_permutation)+'_'\n",
    "    with open(name+'corr_dict.pkl', 'rb') as f:\n",
    "        results[str(percentage)]['correlation'] = pickle.load(f)\n",
    "    with open(name+'frobenius_dict.pkl', 'rb') as f:\n",
    "        results[str(percentage)]['frobenius'] = pickle.load(f)\n",
    "    with open(name+'time_dict.pkl', 'rb') as f:\n",
    "        results[str(percentage)]['time'] = pickle.load(f)   \n",
    "        \n",
    "    non_valid_perm = [] # to remove numerical issues and outliers\n",
    "    values = results[str(percentage)]['frobenius']['steiner']\n",
    "    for i in range(len(values)):\n",
    "        if math.isnan(values[i]):\n",
    "            non_valid_perm.append(i) \n",
    "        elif (percentage==80 and results['80']['time']['nj'][i]>170): #remove NJ time outliers\n",
    "            non_valid_perm.append(i)\n",
    "        elif (percentage == 92.5 and i==40) or (percentage == 90 and i==26): #remove MST time outliers\n",
    "            non_valid_perm.append(i)\n",
    "    valid_perm = np.arange(len(values))\n",
    "    valid_perm = np.delete(valid_perm, non_valid_perm)  \n",
    "    results[str(percentage)]['valid_perm'] = valid_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "297a75d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearanging data structure\n",
    "nj_frobenius = {}\n",
    "steiner_frobenius = {}\n",
    "mst_frobenius = {}\n",
    "\n",
    "nj_time = {}\n",
    "steiner_time = {}\n",
    "mst_time = {}\n",
    "\n",
    "for percentage in percentages:\n",
    "\n",
    "    nj_frobenius[str(percentage)] = np.array(results[str(percentage)]['frobenius']['nj'])[results[str(percentage)]['valid_perm']]\n",
    "    steiner_frobenius[str(percentage)] = np.array(results[str(percentage)]['frobenius']['steiner'])[results[str(percentage)]['valid_perm']]  \n",
    "    mst_frobenius[str(percentage)] = np.array(results[str(percentage)]['frobenius']['mst'])[results[str(percentage)]['valid_perm']]\n",
    "\n",
    "    nj_time[str(percentage)] = np.array(results[str(percentage)]['time']['nj'])[results[str(percentage)]['valid_perm']]\n",
    "    steiner_time[str(percentage)] = np.array(results[str(percentage)]['time']['steiner'])[results[str(percentage)]['valid_perm']]  \n",
    "    mst_time[str(percentage)] = np.array(results[str(percentage)]['time']['mst'])[results[str(percentage)]['valid_perm']]  \n",
    "    \n",
    "    \n",
    "    #to take the mean instead of the \"official\" frobenius, so that we can compare across percentages\n",
    "    threshold = int((100-percentage)/100 * data.shape[0]) # data has 21452 points    \n",
    "    nj_frobenius[str(percentage)] = nj_frobenius[str(percentage)] / np.sqrt(threshold)\n",
    "    steiner_frobenius[str(percentage)] = steiner_frobenius[str(percentage)] / np.sqrt(threshold)\n",
    "    mst_frobenius[str(percentage)] = mst_frobenius[str(percentage)] / np.sqrt(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83365e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04640adf",
   "metadata": {},
   "source": [
    "# Plot the results for the cell age prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c80947",
   "metadata": {},
   "source": [
    "## Plot the distance error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f3e3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot performances\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "x = np.linspace(75, 95, 9)\n",
    "\n",
    "transparency = 0.1\n",
    "divide_factor = 5.0\n",
    "\n",
    "xlabels = ['75', '', '80', '', '85', '', '90', '', '95']\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "y_nj = [nj_frobenius[str(percentage)].mean() for percentage in percentages][::-1]\n",
    "std_nj = np.array([nj_frobenius[str(percentage)].std() for percentage in percentages][::-1])\n",
    "std_nj = std_nj / divide_factor\n",
    "ax.fill_between(x, y_nj - std_nj, y_nj + std_nj, color='tab:green', alpha=transparency)\n",
    "ax.plot(x, y_nj, color='tab:green', label='NJ')\n",
    "\n",
    "y_steiner = [steiner_frobenius[str(percentage)].mean() for percentage in percentages][::-1]\n",
    "std_steiner = np.array([steiner_frobenius[str(percentage)].std() for percentage in percentages][::-1])\n",
    "std_steiner = std_steiner / divide_factor\n",
    "ax.fill_between(x, y_steiner - std_steiner, y_steiner + std_steiner, color='tab:red', alpha=transparency)\n",
    "ax.plot(x, y_steiner, color='tab:red', label = 'HyperSteiner')\n",
    "\n",
    "y_mst = [mst_frobenius[str(percentage)].mean() for percentage in percentages][::-1]\n",
    "std_mst = np.array([mst_frobenius[str(percentage)].std() for percentage in percentages][::-1])\n",
    "std_mst = std_mst / divide_factor\n",
    "ax.fill_between(x, y_mst - std_mst, y_mst + std_mst, color='tab:blue', alpha=transparency)\n",
    "ax.plot(x, y_mst, color='tab:blue', label='MST')\n",
    "\n",
    "plt.xlabel('Percentage of removed data')\n",
    "plt.ylabel('Distance error')\n",
    "title = 'Results/Real/results_realdata_performances'\n",
    "\n",
    "plt.xticks(x, xlabels)\n",
    "ax.legend(loc='upper center').get_frame().set_facecolor('white')\n",
    "\n",
    "ax.set_yticks([0.17, 0.18, 0.19])\n",
    "ax.set_xlim(75, 95)\n",
    "ax.patch.set_alpha(0.5)\n",
    "\n",
    "plt.savefig(title+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f0088",
   "metadata": {},
   "source": [
    "## Plot the CPU time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a12777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time\n",
    "\n",
    "x = np.linspace(75, 95, 9)\n",
    "transparency = 0.1\n",
    "\n",
    "xlabels = ['75', '', '80', '', '85', '', '90', '', '95']\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "y_nj = [nj_time[str(percentage)].mean() for percentage in percentages][::-1]\n",
    "std_nj = np.array([nj_time[str(percentage)].std() for percentage in percentages][::-1])\n",
    "ax.fill_between(x, y_nj - std_nj, y_nj + std_nj, color='tab:green', alpha=transparency)\n",
    "ax.plot(x, y_nj, color='tab:green', label='NJ')\n",
    "\n",
    "y_steiner = [steiner_time[str(percentage)].mean() for percentage in percentages][::-1]\n",
    "std_steiner = np.array([steiner_time[str(percentage)].std() for percentage in percentages][::-1])\n",
    "ax.fill_between(x, y_steiner - std_steiner, y_steiner + std_steiner, color='tab:red', alpha=transparency)\n",
    "ax.plot(x, y_steiner, color='tab:red', label = 'HyperSteiner')\n",
    "\n",
    "y_mst = [mst_time[str(percentage)].mean() for percentage in percentages][::-1]\n",
    "std_mst = np.array([mst_time[str(percentage)].std() for percentage in percentages][::-1])\n",
    "ax.fill_between(x, y_mst - std_mst, y_mst + std_mst, color='tab:blue', alpha=transparency)\n",
    "ax.plot(x, y_mst, color='tab:blue', label = 'MST')\n",
    "\n",
    "plt.xlabel('Percentage of removed data')\n",
    "plt.ylabel('CPU time')\n",
    "title = 'Results/Real/results_realdata_time'\n",
    "\n",
    "plt.xticks(x, xlabels)\n",
    "ax.set_yticks([0, 50, 100, 150])\n",
    "#ax.legend(loc='upper center')\n",
    "ax.set_xlim(75, 95)\n",
    "ax.patch.set_alpha(0.5)\n",
    "\n",
    "plt.savefig(title+'.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
